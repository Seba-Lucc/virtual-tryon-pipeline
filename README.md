# ğŸš€ Virtual Try-On Pipeline

A robust and efficient virtual try-on system that allows users to virtually try on clothing items while preserving their identity and body characteristics.

## âœ¨ Features

- **Person Preservation**: Maintains face, hair, and body proportions
- **Accurate Segmentation**: Uses SegFormer for precise clothing detection
- **Garment-Aware Processing**: Uses actual garment images as visual reference
- **Multiple Processing Modes**: AI inpainting with intelligent fallback
- **Real-time Processing**: Optimized for personal computers
- **High Quality Results**: Professional-grade virtual try-on

## ğŸ¯ Results

![Virtual Try-On Example](modvt/outputs_fixed/fixed_virtual_tryon_result_comparison.png)

## ğŸ› ï¸ Installation

### Prerequisites

- Python 3.8+
- PyTorch
- CUDA (optional, for GPU acceleration)

### Setup

#### Option 1: Automatic Setup (Recommended)

1. Clone the repository:
```bash
git clone https://github.com/Seba-Lucc/virtual-tryon-pipeline.git
cd virtual-tryon-pipeline
```

2. Run the setup script:
```bash
# On macOS/Linux:
./setup.sh

# On Windows:
setup.bat
```

#### Option 2: Manual Setup

1. Clone the repository:
```bash
git clone https://github.com/Seba-Lucc/virtual-tryon-pipeline.git
cd virtual-tryon-pipeline
```

2. Create and activate virtual environment:
```bash
cd modvt
python -m venv modvt
source modvt/bin/activate  # On Windows: modvt\Scripts\activate
```

3. Install dependencies:
```bash
pip install torch torchvision torchaudio
pip install transformers diffusers accelerate
pip install opencv-python pillow numpy
pip install huggingface_hub
```

## ğŸš€ Quick Start

### Basic Usage

1. Place your person image and garment image in the `modvt` directory
2. Update the configuration in `fixed-pipeline.py`:
```python
PERSON_IMAGE = "your_person_image.jpg"
GARMENT_IMAGE = "your_garment_image.png"
```
3. Run the pipeline:
```bash
cd modvt
source modvt/bin/activate
python fixed-pipeline.py
```

### Quick Test (No AI Models)

For a fast test without downloading large AI models:
```bash
python quick-test.py
```

## ğŸ“ Project Structure

```
TRYON/
â”œâ”€â”€ modvt/                          # Main virtual try-on module
â”‚   â”œâ”€â”€ fixed-pipeline.py          # Complete AI-powered pipeline
â”‚   â”œâ”€â”€ quick-test.py              # Fast segmentation test
â”‚   â”œâ”€â”€ enhanced-pipeline.py       # Advanced features pipeline
â”‚   â”œâ”€â”€ outputs_fixed/             # Results directory
â”‚   â”œâ”€â”€ modvt/                     # Python virtual environment
â”‚   â””â”€â”€ *.jpg, *.png              # Input images
â”œâ”€â”€ Virtual tryon/                  # Legacy implementations
â””â”€â”€ README.md                      # This file
```

## ğŸ›ï¸ Configuration

### Main Parameters (in `fixed-pipeline.py`)

```python
class FixedConfig:
    # Input files
    PERSON_IMAGE = "person.jpg"           # Your person image
    GARMENT_IMAGE = "garment.png"         # Garment to try on
    
    # Quality settings
    MAX_RESOLUTION = 768                  # Processing resolution
    INPAINTING_STEPS = 20                 # AI generation steps
    GUIDANCE_SCALE = 7.5                  # AI guidance strength
    
    # Mask settings
    FACE_PROTECTION_EXPAND = 30           # Face protection area
    MASK_BLUR = 5                         # Mask edge smoothing
```

## ğŸ”§ Pipeline Modes

### 1. AI Inpainting Mode (Recommended)
- Uses Stable Diffusion for high-quality results
- Garment-aware initialization
- Professional quality output
- Requires ~2GB VRAM

### 2. Enhanced Traditional Mode (Fallback)
- Color and texture transfer
- No AI models required
- Fast processing
- Good quality results

### 3. Quick Test Mode
- Basic color replacement
- Instant results
- Segmentation verification
- Perfect for testing

## ğŸ“Š Performance

| Mode | Processing Time | Quality | VRAM Usage | Model Download |
|------|----------------|---------|------------|----------------|
| AI Inpainting | ~30 seconds | Excellent | 2GB | ~4GB |
| Enhanced Traditional | ~5 seconds | Good | Minimal | ~500MB |
| Quick Test | ~2 seconds | Basic | Minimal | ~500MB |

## ğŸ¨ Supported Garments

- **T-shirts** âœ… (Primary focus)
- **Shirts** âœ… 
- **Blouses** âœ…
- **Tank tops** âœ…
- **Sweaters** âš ï¸ (Experimental)

## ğŸ”¬ Technical Details

### Segmentation Model
- **Model**: SegFormer B2 (mattmdjaga/segformer_b2_clothes)
- **Classes**: 18 clothing and body part classes
- **Accuracy**: ~95% for upper body garments

### Inpainting Model
- **Model**: Stable Diffusion Inpainting (runwayml/stable-diffusion-inpainting)
- **Input Resolution**: 512x512 (upscaled to original)
- **Features**: Face preservation, garment-aware prompting

## ğŸ› Troubleshooting

### Common Issues

1. **Out of Memory Error**:
   ```bash
   # Reduce resolution in config
   MAX_RESOLUTION = 512
   ```

2. **Slow Processing**:
   ```bash
   # Use quick test mode
   python quick-test.py
   ```

3. **Poor Segmentation**:
   - Ensure good lighting in person image
   - Use images with clear clothing boundaries
   - Check that person is facing forward

4. **Models Not Downloading**:
   ```bash
   # Check internet connection and try:
   huggingface-cli login
   ```

## ğŸ“ Requirements

### Hardware
- **Minimum**: 8GB RAM, CPU processing
- **Recommended**: 16GB RAM, GPU with 4GB+ VRAM
- **Optimal**: 32GB RAM, GPU with 8GB+ VRAM

### Software
- Python 3.8+
- PyTorch 2.0+
- CUDA 11.8+ (for GPU acceleration)

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- [SegFormer](https://github.com/NVlabs/SegFormer) for clothing segmentation
- [Stable Diffusion](https://github.com/runwayml/stable-diffusion) for inpainting
- [Hugging Face](https://huggingface.co/) for model hosting
- [Diffusers](https://github.com/huggingface/diffusers) for pipeline implementation

## ğŸ“§ Contact

- **Developer**: Sebastiano Lucchetti
- **Email**: sebastiano.lucchetti@example.com
- **LinkedIn**: [Your LinkedIn Profile]
- **Project Link**: [https://github.com/yourusername/virtual-tryon-pipeline](https://github.com/yourusername/virtual-tryon-pipeline)

## ğŸ¯ Roadmap

- [ ] Support for lower body garments (pants, skirts)
- [ ] Multiple person support
- [ ] Real-time video processing
- [ ] Mobile app integration
- [ ] Custom garment training
- [ ] Advanced pose handling

---

Made with â¤ï¸ by Sebastiano Lucchetti